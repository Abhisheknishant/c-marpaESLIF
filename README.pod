=for html <a href="https://travis-ci.org/jddurand/c-marpaESLIF"><img src="https://travis-ci.org/jddurand/c-marpaESLIF.svg?branch=master" alt="Travis CI build status" height="18"></a> <a href="https://badge.fury.io/gh/jddurand%2Fc-marpaESLIF"><img src="https://badge.fury.io/gh/jddurand%2Fc-marpaESLIF.svg" alt="GitHub version" height="18"></a> <a href="http://opensource.org/licenses/MIT" rel="nofollow noreferrer"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License MIT" height="18"></a>

=head1 NAME

marpaESLIF - Extended Marpa's Scanless Interface

=head1 DESCRIPTION

marpaESLIF is a Scanless Interface expressed in a BNF format, that is using L<marpaWrapper|https://github.com/jddurand/c-marpaWrapper>, itself being a thin interface on top of L<libmarpa|https://jeffreykegler.github.io/Marpa-web-site/libmarpa.html> parser.

The L<marpaESLIF BNF|https://github.com/jddurand/c-marpaESLIF/tree/master/doc/BNF> is inspired from L<Marpa::R2's DSL|https://metacpan.org/pod/distribution/Marpa-R2/pod/Scanless/DSL.pod>, though with some incompatible changes and many add-ons, in particular:

=over

=item native regular expression support

=item syntactic exception

=item unlimited number of sub-grammars

=item streaming compatible architecture

=back

=head1 Architecture

The ESLIF is nothing else but a I<sparse array> of grammars, identified by an indice called I<level> and starting with value 0, or a description:

           ---------------------------------------------------------
  Indice: | Level 0 | N/A | Level 2 | Level 3 | N/A | Level 5 | ... |
  Name  : | nameof0 | N/A | nameof2 | nameof3 | N/A | nameof5 | ... |
           ---------------------------------------------------------

There B<must> be a grammar at level indice 0. Then any grammar can access any symbol of any other grammar:

           ---------------------------------------------------------
  Indice: | Level 0 | N/A | Level 2 | Level 3 | N/A | Level 5 | ... |
  Name  : | nameof0 | N/A | nameof2 | nameof3 | N/A | nameof5 | ... |
          |---------------------------------------------------------|
  Symbol: | +>X             +>X       +>Xx                          |
  Symbol: | |  Y            |  Y      |  Yy                         |
  Symbol: | |  |            |  |      |  |             +>Zzz        |
          | |  |            |  |      |  |             |   |        |
          | |  |____________|  |______|  |_____________|   |        |
          | |______________________________________________|        |
           ---------------------------------------------------------

If we note a symbol in the form S[i], meaning I<symbol S of grammar level i>, then the schema above say that Y[0] is a reference to X[2], that Y[2] is a reference to Xx[3], that Yy[3] is a reference to Zzz[5], and that Zzz[5] is a reference to Y[0]. Any symbol of any grammar that is accessed I<via a reference> is considered being part of a lexing phase, and the user will have no control until this phase is over, this symbol being recognized or not.

This is why it is required that grammar at level 0 exist: it is considered by the author a common practice that the I<top level> grammar should be at level 0. Though technically this is not absolutely required -; In fact, it is possible to start parsing by specifying I<another> grammar but the one at level 0 as a starting grammar.

The lifetime of parsing, for a given I<location> in the top-level grammar, consist by assigning a set of symbols (these are called I<alternatives>), commiting them (we say that we I<complete> the set of alternatives), and move on. A Scanless Interface mean that you do not have to write your own analysis of input: grammars give definition of what is expected, and the interface have the possbility to determine all the alternatives for you, commiting them, and move on in the input stream. We say input stream: this is another dimension (we suppose from now on that the top-level grammar is at level 0):

           ---------------------------------------------------  STREAM MANAGEMENT
 Rule:    | X ::= x y                                         |
          |---------------------------------------------------| STEP 0
          | Location is start of rule X[0]:                   |
          | X ::= . x y                                       |
          | Suppose that expected "terminals" are T1 and T2:  |
          |---------------------------------------------------| STEP 1
          | Try to match T1                                   |
          |   Nothing yet in the stream ?                     |<-----> Stream reader callback
          |   T1 may match but we are not sure                |<-----> Stream reader callback
          |   Repeat until T1 matches for sure or not         |
          |---------------------------------------------------| STEP 2
          | Try to match T2                                   |
          |   T2 may match but we are not sure                |<-----> Stream reader callback
          |   Repeat until T2 matches for sure or not         |
          |---------------------------------------------------|
          | No match ? End of scanning                        | STEP 3
          | Match ? Commit T1 and T2 and continue             |
           ---------------------------------------------------

This stream management is transversal to any grammar: As soon as "terminal" is in reality a referenced symbol, a sub-recognizer is instanciated and it is sharing the stream with is parent:


                    TOP RECOGNIZER ON GRAMMAR LEVEL 0

           ---------------------------------------------------            STREAM MANAGEMENT
          | Rule is X ::= x y                                 |
          |---------------------------------------------------| STEP 0.0
          | Location is start of rule X[0]:                   |
          | X ::= . x y                                       |
          | Suppose that expected "terminals" are T1 and T2:  |
          |---------------------------------------------------| STEP 0.1
          | Try to match T1                                   |
          |   Nothing yet in the stream ?                     |<-----> Stream reader callback
          |   T1 may match but we are not sure                |<-----> Stream reader callback
          |   Repeat until T1 matches for sure or not         |
          |---------------------------------------------------| STEP 0.2
          | Try to match T2                                   |
          |   T2 is a referenced symbol in grammar n          |
           ---------------------------------------------------

                    SUB-RECOGNIZER ON GRAMMAR LEVEL n

             -------------------------------------------------
            | Rule is T2 :[n]:= a b                           |
            |-------------------------------------------------| STEP 1.0
            | Location is start of rule T2[n]:                |
            | T2 :[n]:= . a b                                 |
            | Suppose that expected "terminals" are U1 and U2:|
            |-------------------------------------------------| STEP 1.1
            | Try to match U1                                 |
            |   Nothing yet in the stream ?                   |<-----> Stream reader callback
            |   U1 may match but we are not sure              |<-----> Stream reader callback
            |   Repeat until U1 matches for sure or not       |
            |-------------------------------------------------| STEP 1.2
            | Try to match U2                                 |
            |   U2 may match but we are not sure              |<-----> Stream reader callback
            |   Repeat until U2 matches for sure or not       |
            |-------------------------------------------------|
            | No match ? End of scanning for T2[n]            | STEP 1.3
            | Match ? Commit U1 and/or U2 and continue        |
             -------------------------------------------------
            | Do internal valuation                           | STEP 1.4
             -------------------------------------------------

                 BACK TO TOP RECOGNIZER ON GRAMMAR LEVEL 0

           ---------------------------------------------------
          | No match ? End of scanning                        | STEP 0.3
          | Match ? Commit T1 and/or T2 and continue          |
          | If T2 matches it is a parse tree value            |
           ---------------------------------------------------

And this is recursive: there will as many sub-recognizers instanciated as there are sub-grammars involved. For instance if terminal C<U2> above is a referenced symbol at grammar level C<l>, a second sub-recognizer will be instanced by the first sub-recognizer. Every child recognizer is sharing all needed transveral information, that is everything about stream management. The main difference between the top recognizer and any child recognizer is that a child recognizer is always doing an internal valuation to retreive the span in the input stream for, and give that back to its parent.

The internal valuation is a forced mode that is concatenating all matched bytes in the input stream.

You might say, why explicitely doing an internal valuation: the match is where sub-recognizer started and where it ended. No, because any grammar is independant can have it own I<discard> mechanism. This mean that what a sub-recognizer matched may be shorter than the number of bytes effectively consumed from the input stream. So we have introduced the notion of I<discard>:

=head1 SEE ALSO

L<marpaESLIF_BNF|https://github.com/jddurand/c-marpaESLIF/tree/master/doc/BNF>
